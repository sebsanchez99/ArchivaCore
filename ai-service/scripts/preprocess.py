import os
import pandas as pd
import spacy
import string
import re

# ðŸ“Œ Cargar modelo de spaCy en inglÃ©s
nlp = spacy.load("en_core_web_sm")

# ðŸ“Œ ConfiguraciÃ³n de archivos
DATA_PATH = os.path.abspath(os.path.join('data', 'Resume.csv'))
CLEAN_DATA_PATH = os.path.abspath(os.path.join('data', 'Resume_clean.csv'))

# ðŸ“Œ Cargar el dataset con manejo de codificaciÃ³n
df = pd.read_csv(DATA_PATH, encoding="utf-8")

# ðŸ”¹ Eliminar filas con valores nulos en 'Resume_str'
df = df.dropna(subset=['Resume_str'])

# ðŸ”¹ Eliminar columna 'Resume_html' si no se usarÃ¡
df = df.drop(columns=['Resume_html'], errors='ignore')

# ðŸ”¹ Rellenar valores nulos restantes en Resume_str (por seguridad)
df['Resume_str'] = df['Resume_str'].fillna('')

# ðŸ”¹ FunciÃ³n para limpiar y lematizar texto con spaCy
def clean_text(text):
    text = text.lower()
    text = re.sub(r'\d+', '', text)  # Eliminar nÃºmeros
    text = text.translate(str.maketrans('', '', string.punctuation))  # Eliminar puntuaciÃ³n
    text = re.sub(r'\s+', ' ', text).strip()  # Eliminar espacios extra

    # Procesar con spaCy
    doc = nlp(text)
    words = [token.lemma_ for token in doc if not token.is_stop]  # LematizaciÃ³n y eliminaciÃ³n de stopwords
    
    return ' '.join(words)

# ðŸ”¹ Aplicar limpieza de texto
df['Resume_clean'] = df['Resume_str'].apply(clean_text)

# ðŸ”¹ Eliminar filas donde Resume_clean sea nulo o vacÃ­o
df = df.dropna(subset=['Resume_clean'])
df = df[df['Resume_clean'].str.strip() != '']

# ðŸ“Œ Guardar el dataset limpio
os.makedirs(os.path.dirname(CLEAN_DATA_PATH), exist_ok=True)
df.to_csv(CLEAN_DATA_PATH, index=False, encoding="utf-8")

print("âœ… Limpieza completada. Archivo guardado en:", CLEAN_DATA_PATH)